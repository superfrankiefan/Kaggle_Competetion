{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a200e7d5d445186de873752a5f25abad12004d6e"
   },
   "source": [
    "### 给定一个参考时间点，根据每张卡距离该参考时间点最近的3个月交易/刷卡数据，以及该参考时间点之后两个月的交易/刷卡数据来计算每张卡（主人）的忠诚度。除此之外，还有额外消费商店相关的数据，如商店分类、商店交易量等信息。\n",
    "************************************************************************************************************************************************\n",
    "2018.12.07: 审题的结果是一个时间序列相关的问题。但是看到圈内都用lightgbm做了回归预测，所以个人感觉有空间提升。\n",
    "************************************************************************************************************************************************\n",
    "数据的理解：\n",
    "* train：card_id, first_purchase_date, f1, f2, f3, target(loyalty)\n",
    "* test: card_id, first_purchase_date, f1, f2, f3, target(loyalty)\n",
    "* history/new: card_id, month_lag, purchase_date, authorized_flag, category_3, installments, category_1, merchant_category_id, subsector_id, merchant_id, purchase_amount, city_id, state_id, category_2 \n",
    "* merchant: merchant_id, merchant_group_id, merchant_category_id, subsector_id, numerical_1, numerical_2, category_1, most_recent_sales_range, most_recent_purchases_range, avg_sales_lag3, avg_purchases_lag3, active_months_lag3, avg_sales_lag6 , ,avg_purchases_lag6, active_months_lag6, avg_sales_lag12, avg_purchases_lag12, active_months_lag12, category_4, city_id, state_id, category_2\n",
    "************************************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data_Dictionary.xlsx', 'new_merchant_transactions.csv', 'test.csv', 'tmp_data.csv', 'merchants.csv', 'historical_transactions.csv', 'train.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"../dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common functions\n",
    "def binaries(value):\n",
    "    if value == 'Y':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil import rrule\n",
    "def get_month_span(month):\n",
    "    baseline = '2018-02'\n",
    "    x = datetime.strptime(baseline, '%Y-%m')\n",
    "    y = datetime.strptime(month, '%Y-%m')\n",
    "    months = rrule.rrule(rrule.MONTHLY, dtstart=y, until=x).count()\n",
    "    return months\n",
    "\n",
    "def get_day_span(date):\n",
    "    baseline = '2018-03-01 00:00:00'\n",
    "    x = datetime.strptime(baseline, '%Y-%m-%d %H:%M:%S')\n",
    "    y = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "    return (x - y).days\n",
    "\n",
    "def get_days_from_purchase(date):\n",
    "    baseline = '2018-03-01 00:00:00'\n",
    "    x = datetime.strptime(baseline, '%Y-%m-%d %H:%M:%S')\n",
    "    days = x - date\n",
    "    return days\n",
    "\n",
    "#from collections import Counter\n",
    "#s = hist_data['category_2'].tolist()\n",
    "#word_counts = Counter(s)\n",
    "#top_three = word_counts.most_common(3)\n",
    "#print(top_three)\n",
    "#hist_data.loc[hist_data['merchant_id'] == 'M_ID_00a6ca8a8a']['merchant_id'].count()\n",
    "# history transaction data\n",
    "#f_history = open('../dataset/historical_transactions.csv')\n",
    "#history_data_chunk = pd.read_csv(f_history, iterator=True)\n",
    "#loop = True\n",
    "#chunkSize = 100000\n",
    "#chunks = []\n",
    "#while loop:\n",
    "#    try:\n",
    "#        chunk = history_data_chunk.get_chunk(chunkSize)\n",
    "#        chunks.append(chunk)\n",
    "#    except StopIteration:\n",
    "#        loop = False\n",
    "#history_transaction = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merchant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334696 entries, 0 to 334695\n",
      "Data columns (total 27 columns):\n",
      "m_id              334696 non-null category\n",
      "m_gid             334696 non-null category\n",
      "m_cid             334696 non-null category\n",
      "m_sid             334696 non-null category\n",
      "m_num1            334696 non-null float64\n",
      "m_num2            334696 non-null float64\n",
      "m_cat1            334696 non-null category\n",
      "m_mrsr            334696 non-null category\n",
      "m_mrpr            334696 non-null category\n",
      "m_asl3            334696 non-null float64\n",
      "m_apl3            334696 non-null float64\n",
      "m_aml3            334696 non-null int64\n",
      "m_asl6            334696 non-null float64\n",
      "m_apl6            334696 non-null float64\n",
      "m_aml6            334696 non-null int64\n",
      "m_asl12           334696 non-null float64\n",
      "m_apl12           334696 non-null float64\n",
      "m_aml12           334696 non-null int64\n",
      "m_cat4            334696 non-null bool\n",
      "m_city            334696 non-null category\n",
      "m_state           334696 non-null category\n",
      "m_cat2            334696 non-null category\n",
      "m_group_count     334696 non-null int64\n",
      "m_cat_count       334696 non-null int64\n",
      "m_subset_count    334696 non-null int64\n",
      "m_city_count      334696 non-null int64\n",
      "m_state_count     334696 non-null int64\n",
      "dtypes: bool(1), category(10), float64(8), int64(8)\n",
      "memory usage: 65.3 MB\n"
     ]
    }
   ],
   "source": [
    "# merchant data\n",
    "merchants_data = pd.read_csv(\"../dataset/merchants.csv\")\n",
    "# fillna\n",
    "avg_sales_lag3_mean = merchants_data['avg_sales_lag3'].mean()\n",
    "merchants_data['avg_sales_lag3'].fillna(avg_sales_lag3_mean, inplace=True)\n",
    "avg_sales_lag6_mean = merchants_data['avg_sales_lag6'].mean()\n",
    "merchants_data['avg_sales_lag6'].fillna(avg_sales_lag6_mean, inplace=True)\n",
    "avg_sales_lag12_mean = merchants_data['avg_sales_lag12'].mean()\n",
    "merchants_data['avg_sales_lag12'].fillna(avg_sales_lag12_mean, inplace=True)\n",
    "merchants_data['category_2'].fillna(0, inplace=True)\n",
    "# change date type\n",
    "merchants_data['merchant_id'] = merchants_data['merchant_id'].astype('category')\n",
    "merchants_data['merchant_group_id'] = merchants_data['merchant_group_id'].astype('category')\n",
    "merchants_data['merchant_category_id'] = merchants_data['merchant_category_id'].astype('category')\n",
    "merchants_data['subsector_id'] = merchants_data['subsector_id'].astype('category')\n",
    "merchants_data['category_1'] = merchants_data['category_1'].astype('category')\n",
    "merchants_data['most_recent_sales_range'] = merchants_data['most_recent_sales_range'].astype('category')\n",
    "merchants_data['most_recent_purchases_range'] = merchants_data['most_recent_purchases_range'].astype('category')\n",
    "merchants_data['category_2'] = merchants_data['category_2'].astype('category')\n",
    "merchants_data['category_4'] = merchants_data['category_4'].apply(binaries).astype('bool')\n",
    "merchants_data['city_id'] = merchants_data['city_id'].astype('category')\n",
    "merchants_data['state_id'] = merchants_data['state_id'].astype('category')\n",
    "\n",
    "### construct features\n",
    "# group: merchant number of each group\n",
    "# category: merchant number of each category\n",
    "# subsector: merchant number of each subsector\n",
    "# city: merchant number of each city\n",
    "# state: merchant number of each state\n",
    "merchants_group = {k: v for k, v in merchants_data['merchant_group_id'].value_counts().iteritems()}\n",
    "merchants_category = {k: v for k, v in merchants_data['merchant_category_id'].value_counts().iteritems()}\n",
    "merchants_subsector = {k: v for k, v in merchants_data['subsector_id'].value_counts().iteritems()}\n",
    "merchants_city = {k: v for k, v in merchants_data['city_id'].value_counts().iteritems()}\n",
    "merchants_state = {k: v for k, v in merchants_data['state_id'].value_counts().iteritems()}\n",
    "\n",
    "def count_group(x):\n",
    "    return merchants_group[x]\n",
    "def count_cat(x):\n",
    "    return merchants_category[x]\n",
    "def count_subset(x):\n",
    "    return merchants_subsector[x]\n",
    "def count_city(x):\n",
    "    return merchants_city[x]\n",
    "def count_state(x):\n",
    "    return merchants_state[x]\n",
    "\n",
    "merchants_data['group_count'] = merchants_data['merchant_group_id'].apply(count_group).astype(np.int64)\n",
    "merchants_data['cat_count'] = merchants_data['merchant_category_id'].apply(count_cat).astype(np.int64)\n",
    "merchants_data['subset_count'] = merchants_data['subsector_id'].apply(count_subset).astype(np.int64)\n",
    "merchants_data['city_count'] = merchants_data['city_id'].apply(count_city).astype(np.int64)\n",
    "merchants_data['state_count'] = merchants_data['state_id'].apply(count_state).astype(np.int64)\n",
    "\n",
    "# rename features\n",
    "merchants_data = merchants_data.rename(columns = {'merchant_group_id':'m_gid', \n",
    "                                                  'merchant_category_id':'m_cid', \n",
    "                                                  'subsector_id':'m_sid', \n",
    "                                                  'numerical_1':'m_num1', \n",
    "                                                  'numerical_2':'m_num2', \n",
    "                                                  'category_1':'m_cat1', \n",
    "                                                  'category_2':'m_cat2',\n",
    "                                                  'category_4':'m_cat4',\n",
    "                                                  'most_recent_sales_range':'m_mrsr', \n",
    "                                                  'most_recent_purchases_range':'m_mrpr', \n",
    "                                                  'avg_sales_lag3':'m_asl3', \n",
    "                                                  'avg_purchases_lag3':'m_apl3', \n",
    "                                                  'active_months_lag3':'m_aml3', \n",
    "                                                  'avg_sales_lag6':'m_asl6', \n",
    "                                                  'avg_purchases_lag6':'m_apl6', \n",
    "                                                  'active_months_lag6':'m_aml6',\n",
    "                                                  'avg_sales_lag12':'m_asl12', \n",
    "                                                  'avg_purchases_lag12':'m_apl12', \n",
    "                                                  'active_months_lag12':'m_aml12', \n",
    "                                                  'city_id':'m_city', \n",
    "                                                  'state_id':'m_state', \n",
    "                                                  'group_count':'m_group_count', \n",
    "                                                  'cat_count':'m_cat_count', \n",
    "                                                  'subset_count':'m_subset_count', \n",
    "                                                  'city_count':'m_city_count', \n",
    "                                                  'state_count':'m_state_count', \n",
    "                                                  'merchant_id':'m_id'})\n",
    "merchants_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "hist_data = pd.read_csv('../dataset/historical_transactions.csv')\n",
    "# fillna\n",
    "hist_data['category_2'].fillna(1.0, inplace=True)\n",
    "hist_data['category_3'].fillna('A', inplace=True)\n",
    "hist_data['merchant_id'].fillna('M_ID_00a6ca8a8a', inplace=True)\n",
    "# change data type\n",
    "hist_data['authorized_flag'] = hist_data['authorized_flag'].apply(binaries).astype('bool')\n",
    "hist_data['card_id'] = hist_data['card_id'].astype('category')\n",
    "hist_data['city_id'] = hist_data['city_id'].astype('category')\n",
    "hist_data['category_1'] = hist_data['category_1'].apply(binaries).astype('bool')\n",
    "hist_data['category_2'] = hist_data['category_2'].astype('int').astype('category')\n",
    "hist_data['category_3'] = hist_data['category_3'].astype('category')\n",
    "hist_data['merchant_category_id'] = hist_data['merchant_category_id'].astype('category')\n",
    "hist_data['merchant_id'] = hist_data['merchant_id'].astype('category')\n",
    "hist_data['purchase_date'] = pd.to_datetime(hist_data['purchase_date'])\n",
    "hist_data['state_id'] = hist_data['state_id'].astype('category')\n",
    "hist_data['subsector_id'] = hist_data['subsector_id'].astype('category')\n",
    "\n",
    "# construct features\n",
    "# purchase_date: year, month, day\n",
    "# card_id: agg total numbers\n",
    "hist_data['purchase_date'] = hist_data['purchase_date'].apply(get_days_from_purchase)\n",
    "card_purchase_count = {k: v for k, v in hist_data['card_id'].value_counts().iteritems()}\n",
    "def count_purchase(x):\n",
    "    return card_purchase_count[x]\n",
    "hist_data['card_count'] = hist_data['card_id'].apply(count_purchase).astype(np.int64)\n",
    "hist_data.drop(columns=['purchase_date'], inplace=True)\n",
    "# rename features\n",
    "hist_data = hist_data.rename(columns={'card_id':'c_id', \n",
    "                                      'authorized_flag': 'c_af',\n",
    "                                      'city_id': 'c_city', \n",
    "                                      'state_id': 'c_state',\n",
    "                                      'subsector_id': 'c_ms',\n",
    "                                      'category_1':'c_cat1', \n",
    "                                      'category_2':'c_cat2', \n",
    "                                      'category_3':'c_cat3', \n",
    "                                      'installments':'c_inst', \n",
    "                                      'merchant_category_id':'c_mcid', \n",
    "                                      'merchant_id':'m_id', \n",
    "                                      'month_lag': 'c_ml', \n",
    "                                      'purchase_amount':'c_pa', \n",
    "                                      'card_count':'c_cc', \n",
    "                                      'purchase_ref_days':'c_prd'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_data = pd.read_csv(\"../dataset/train.csv\")\n",
    "# change data type\n",
    "train_data['first_active_month'] = train_data['first_active_month'].apply(get_month_span)\n",
    "train_data['card_id'] = train_data['card_id'].astype('category')\n",
    "train_data['feature_1'] = train_data['feature_1'].astype('category')\n",
    "train_data['feature_2'] = train_data['feature_2'].astype('category')\n",
    "train_data['feature_3'] = train_data['feature_3'].astype('category')\n",
    "# rename feature\n",
    "train_data = train_data.rename(columns={'first_active_month':'t_days', \n",
    "                                        'card_id':'c_id', \n",
    "                                        'feature_1':'t_f1', \n",
    "                                        'feature_2':'t_f2', \n",
    "                                        'feature_3':'t_f3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_data = pd.read_csv(\"../dataset/test.csv\")\n",
    "# fillna\n",
    "test_data['first_active_month'].fillna('2018-02', inplace=True)\n",
    "# change data type\n",
    "test_data['first_active_month'] = test_data['first_active_month'].apply(get_month_span)\n",
    "test_data['card_id'] = test_data['card_id'].astype('category')\n",
    "test_data['feature_1'] = test_data['feature_1'].astype('category')\n",
    "test_data['feature_2'] = test_data['feature_2'].astype('category')\n",
    "test_data['feature_3'] = test_data['feature_3'].astype('category')\n",
    "test_data = test_data.rename(columns={'first_active_month':'t_days', \n",
    "                                        'card_id':'c_id', \n",
    "                                        'feature_1':'t_f1', \n",
    "                                        'feature_2':'t_f2', \n",
    "                                        'feature_3':'t_f3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "5f04106153b0726a460ccef638f29a0be3f9b7e4"
   },
   "outputs": [],
   "source": [
    "tmp = pd.merge(train_data, hist_data, how='left', on='c_id')\n",
    "tmp = pd.merge(tmp, merchants_data, how='left', on='m_id')\n",
    "tmp['c_id'] = tmp['c_id'].astype('category')\n",
    "tmp['m_id'] = tmp['m_id'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp = tmp['target'].values\n",
    "X_tmp = tmp.drop(columns=['target', 'c_id', 'm_id'], axis=1)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_tmp, y_tmp, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(X_tmp, y_tmp)\n",
    "watchlist = [d_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttraining's rmse: 3.38946\n",
      "[10]\ttraining's rmse: 3.30439\n",
      "[15]\ttraining's rmse: 3.23076\n",
      "[20]\ttraining's rmse: 3.18346\n",
      "[25]\ttraining's rmse: 3.14676\n",
      "[30]\ttraining's rmse: 3.11005\n",
      "[35]\ttraining's rmse: 3.07428\n",
      "[40]\ttraining's rmse: 3.04652\n",
      "[45]\ttraining's rmse: 3.01365\n",
      "[50]\ttraining's rmse: 2.98229\n",
      "[55]\ttraining's rmse: 2.95676\n",
      "[60]\ttraining's rmse: 2.92729\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.5 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 2**8,\n",
    "        'max_depth': 20,\n",
    "        'metric' : 'rmse'\n",
    "}\n",
    "model = lgb.train(params, train_set=d_train, num_boost_round=60, valid_sets=watchlist, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test_data, hist_data, how='left', on='c_id')\n",
    "test = pd.merge(test, merchants_data, how='left', on='m_id')\n",
    "test['c_id'] = test['c_id'].astype('category')\n",
    "test['m_id'] = test['m_id'].astype('category')\n",
    "ids = test['c_id'].values\n",
    "test_set = test.drop(columns=['c_id', 'm_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11600086 entries, 0 to 11600085\n",
      "Data columns (total 42 columns):\n",
      "t_days            int64\n",
      "t_f1              category\n",
      "t_f2              category\n",
      "t_f3              category\n",
      "c_af              bool\n",
      "c_city            category\n",
      "c_cat1            bool\n",
      "c_inst            int64\n",
      "c_cat3            category\n",
      "c_mcid            category\n",
      "c_ml              int64\n",
      "c_pa              float64\n",
      "c_cat2            category\n",
      "c_state           category\n",
      "c_ms              category\n",
      "c_cc              int64\n",
      "m_gid             category\n",
      "m_cid             category\n",
      "m_sid             category\n",
      "m_num1            float64\n",
      "m_num2            float64\n",
      "m_cat1            category\n",
      "m_mrsr            category\n",
      "m_mrpr            category\n",
      "m_asl3            float64\n",
      "m_apl3            float64\n",
      "m_aml3            int64\n",
      "m_asl6            float64\n",
      "m_apl6            float64\n",
      "m_aml6            int64\n",
      "m_asl12           float64\n",
      "m_apl12           float64\n",
      "m_aml12           int64\n",
      "m_cat4            bool\n",
      "m_city            category\n",
      "m_state           category\n",
      "m_cat2            category\n",
      "m_group_count     int64\n",
      "m_cat_count       int64\n",
      "m_subset_count    int64\n",
      "m_city_count      int64\n",
      "m_state_count     int64\n",
      "dtypes: bool(3), category(18), float64(9), int64(12)\n",
      "memory usage: 2.2 GB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_set)\n",
    "subm = pd.DataFrame()\n",
    "subm['card_id'] = ids\n",
    "subm['target'] = predictions\n",
    "subm.to_csv('../dataset/submission.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = subm.groupby('card_id')['target'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame({'card_id':target.index, 'target':target.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "r.to_csv('../dataset/submission.csv', index=False, float_format = '%.5f')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
